import logging
import os
import sys
import threading
import time
from collections import deque
from concurrent import futures
from pathlib import Path

import grpc

root_directory = Path(__file__).resolve().parent.parent
sys.path.append(str(root_directory))

from grpc_start import lock_pb2, lock_pb2_grpc, raft_pb2_grpc, raft_server  # noqa: E402

# The server is required to have the following functionality:
# 1.  Create 100 files that clients can write. The file name should strictly follow this format "file_0", "file_1", ..., "file_99".
# 2.  Maintain one lock object, we use one lock to protect all the files for the sake of simplicity. In real world, there can be one lock per file.
# 3.  Receiving packets from a client and spawning a new thread to handle it. This will allow for multiple clients to connect at the same time. To note that, servers
# generated by  rpcgen  do not have multi-threading, you have to implement it.

DEBUG = True
LOCK_TIMEOUT = 4


class LockServer(lock_pb2_grpc.LockServiceServicer):
    def __init__(self, ip="localhost", port=50051):
        self.lock_owner = None  # does not need to be synced independently; always equal to waiting_list[0]

        self.clients = {}  # needs to be synced - 'add client' action, 'increment client's expected seq number' action
        self.waiting_list = (
            deque()
        )  # needs to be synced - 'add', 'remove client id' action
        self.newClientId = 1  # needs to be synced - 'increment' action
        self.appends = (
            deque()
        )  # needs to be synced - 'add operation' action, 'execute all' action
        # so any time any of these change, it's a log entry

        self.lock_timer = threading.Timer(
            LOCK_TIMEOUT, self.force_release_lock
        )  # would be difficult and stupid to sync
        # lock timer DOES NOT GET STARTED NOW: only starts with the very first call to lock_acquire
        self.ip = ip
        self.port = port

    def start_lock_timer(self):
        """Start or restart the lock timeout timer for the current lock owner."""
        if DEBUG:
            print(
                f"Server: start_lock_timer called: lock_owner={self.lock_owner}, waiting_list={self.waiting_list}"
            )
        if self.lock_timer:
            self.lock_timer.cancel()
        self.lock_timer = threading.Timer(LOCK_TIMEOUT, self.force_release_lock)
        self.lock_timer.start()

    def force_release_lock(self):
        """Release the lock if the owner is unresponsive."""
        if DEBUG:
            print(
                f"Server: force_release_lock called: lock_owner={self.lock_owner}, waiting_list={self.waiting_list}"
            )
        if self.lock_owner:
            if DEBUG:
                print(f"Lock timed out for client {self.lock_owner}. Releasing lock.")
            self.lock_owner = None
            if self.waiting_list:
                self.grant_lock_to_next_client()

            self.appends = (
                deque()
            )  # delete any append operations that weren't carried out

    def grant_lock_to_next_client(self):
        """Grant the lock to the next client in the queue."""
        if DEBUG:
            print(
                f"Server: grant_lock_to_next_client called: lock_owner={self.lock_owner}, waiting_list={self.waiting_list}"
            )
        if self.waiting_list:
            self.waiting_list.popleft()
            if self.waiting_list:
                self.lock_owner = self.waiting_list[0]
            else:
                self.lock_owner = None
            print(f"Lock granted to client {self.lock_owner}")
            self.start_lock_timer()

    def check_client_seq(self, client_id, request_seq) -> lock_pb2.Response:
        """Check if a) the client has called client_init beforehand, and b) if the request is a duplicate or not"""
        if client_id in self.clients:
            client_seq = self.clients[client_id]["seq"]
            if request_seq != client_seq:
                return lock_pb2.Response(
                    status=lock_pb2.Status.SEQ_ERROR, seq=client_seq
                )
            else:
                return None  # no error here, carry on
        else:
            return lock_pb2.Response(
                status=lock_pb2.Status.CLIENT_NOT_INIT, seq=client_seq
            )

    def client_init(self, request, context):
        client_ip = context.peer()
        client_id = self.newClientId
        self.newClientId += 1
        client_seq = 1  # sequence number of next expected request

        self.clients[client_id] = {"ip": client_ip, "seq": client_seq}
        if DEBUG:
            print("client_init received: " + str(request.rc))
            print("connected clients: " + str(self.clients))
        return lock_pb2.Int(rc=client_id, seq=client_seq)

    def lock_acquire(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq

        check_response = self.check_client_seq(client_id, request_seq)
        if check_response:
            return check_response

        client_seq = self.clients[client_id]["seq"]

        print(f"Server: lock_acquire received: {request.client_id}")

        if self.lock_owner is None:
            self.waiting_list.append(request.client_id)
            self.lock_owner = client_id
            self.start_lock_timer()
            self.clients[client_id]["seq"] += 1
            return lock_pb2.Response(
                status=lock_pb2.Status.SUCCESS, seq=self.clients[client_id]["seq"]
            )
        elif self.lock_owner == request.client_id:
            print(f"Client {client_id} already has the lock.")
            self.start_lock_timer()
            self.clients[client_id]["seq"] += 1
            return lock_pb2.Response(
                status=lock_pb2.Status.SUCCESS, seq=self.clients[client_id]["seq"]
            )

        self.waiting_list.append(request.client_id)
        while True:
            if self.waiting_list[0] == request.client_id:
                # essentially, head of waiting list is always current owner
                # could, in theory, remove self.lock_owner entirely but this might get confusing real fast
                self.clients[client_id]["seq"] += 1
                print(f"LOCK OWNER: {self.lock_owner}")

                return lock_pb2.Response(
                    status=lock_pb2.Status.SUCCESS, seq=client_seq + 1
                )
            else:
                time.sleep(0.1)

    def lock_release(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq

        check_response = self.check_client_seq(client_id, request_seq)
        if check_response:
            return check_response

        print("lock_release received: " + str(request.client_id))

        if self.lock_owner == request.client_id:
            self.grant_lock_to_next_client()
            # resets timer, as this is a call from the current lock owner, proving that client is alive
            self.clients[client_id]["seq"] += 1
            self.start_lock_timer()

            # execute all stashed changes to files - this also removes all append entries
            while self.appends:
                file_path, bytes = self.appends.popleft()

                with open(file_path, "ab") as file:
                    file.write(bytes)

            return lock_pb2.Response(
                status=lock_pb2.Status.SUCCESS, seq=self.clients[client_id]["seq"]
            )
        else:
            self.clients[client_id]["seq"] += 1
            # good idea to have this anyhow, as client could call release before ever calling acquire
            return lock_pb2.Response(
                status=lock_pb2.Status.FAILURE, seq=self.clients[client_id]["seq"]
            )

    def file_append(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq

        check_response = self.check_client_seq(client_id, request_seq)
        if check_response:
            return check_response

        print(
            f"Server: file_append received: {request.client_id}, {request.filename}, deque: {self.waiting_list}"
        )

        self.clients[client_id]["seq"] += 1
        if self.lock_owner == request.client_id:
            # resets timer, as this is a call from the current lock owner, proving that client is alive
            self.start_lock_timer()

            filename = request.filename
            file_path = f"./files/{filename}"

            if os.path.isfile(file_path):
                # add file append operation to appends queue
                self.appends.append((file_path, request.content))

                return lock_pb2.Response(
                    status=lock_pb2.Status.SUCCESS,
                    seq=self.clients[client_id]["seq"],
                )
            else:
                if DEBUG:
                    print(f"File {filename} error.")
                return lock_pb2.Response(
                    status=lock_pb2.Status.FILE_ERROR,
                    seq=self.clients[client_id]["seq"],
                )
        else:
            if DEBUG:
                print(f"Lock expired for client {client_id}.")
            return lock_pb2.Response(
                status=lock_pb2.Status.LOCK_EXPIRED, seq=self.clients[client_id]["seq"]
            )

    def keep_alive(self, request, context) -> lock_pb2.Response:
        """Handle keep-alive messages from the client."""
        client_id = request.client_id
        if client_id == self.lock_owner:
            print(f"Keep-alive received from client {client_id}. Resetting lock timer.")
            self.start_lock_timer()
            self.clients[client_id]["seq"] += 1
            return lock_pb2.Response(
                status=lock_pb2.Status.SUCCESS, seq=self.clients[client_id]["seq"]
            )
        else:
            return lock_pb2.Response(
                status=lock_pb2.Status.FAILURE, seq=self.clients[client_id]["seq"]
            )

    def client_close(self, request, context):
        # get process id and remove from set
        client_id = request.rc
        if client_id in self.clients:
            while self.lock_owner == client_id:
                time.sleep(0.01)
            del self.clients[client_id]

        if DEBUG:
            print("client_close received: " + str(request.rc))
            print("connected clients: " + str(self.clients))
            print()
        return lock_pb2.Int(rc=client_id, seq=0)

    def serve(self):
        self.raft_server = raft_server.RaftServer(self.ip, self.port)
        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
        raft_pb2_grpc.add_RaftServiceServicer_to_server(self.raft_server, self.server)
        lock_pb2_grpc.add_LockServiceServicer_to_server(self, self.server)

        self.server.add_insecure_port(f"[::]:{self.port}")
        self.server.start()
        print("Server started, listening on ", self.port)
        time.sleep(5)
        print(f"Raft server {self.port} found leader: {self.raft_server.find_leader()}")

    def stop(self):
        self.lock_timer.cancel()
        self.server.stop(0)

    def where_is_server(self, request, context):
        ip = "0.0.0.0"
        port = -1
        return lock_pb2.ServerLocation(ip=ip, port=port)


def create_files(n=100):
    # needs to be modified to account for multiple servers

    # create directory & files if necessary:
    if not os.path.exists("./files"):
        os.makedirs("./files")

        for i in range(n):
            with open("./files/file_" + str(i), "w") as f:
                f.write("")


def reset_files(n=100):
    # they might or might not exist:
    for i in range(n):
        with open("./files/file_" + str(i), "w") as f:
            f.write("")


if __name__ == "__main__":
    create_files()  # presumably the server object should do this, rather than it being randomly outside??
    logging.basicConfig()
    server = LockServer()
    server.serve()
