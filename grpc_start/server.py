from concurrent import futures
import logging
import os
import sys
from pathlib import Path
import threading
import grpc
import time
from collections import deque

root_directory = Path(__file__).resolve().parent.parent
sys.path.append(str(root_directory))

from grpc_start import lock_pb2_grpc
from grpc_start import lock_pb2

# The server is required to have the following functionality:
# 1.  Create 100 files that clients can write. The file name should strictly follow this format "file_0", "file_1", ..., "file_99".
# 2.  Maintain one lock object, we use one lock to protect all the files for the sake of simplicity. In real world, there can be one lock per file.
# 3.  Receiving packets from a client and spawning a new thread to handle it. This will allow for multiple clients to connect at the same time. To note that, servers
# generated by  rpcgen  do not have multi-threading, you have to implement it.

DEBUG = True

class LockServer(lock_pb2_grpc.LockServiceServicer):
    # track connected clients in a Set
    def __init__(self):
        # self.lock = threading.Lock()
        self.lock_owner = None
        self.clients = {}
        self.waiting_list = deque()
        self.seq = 1

    def client_init(self, request, context): 
        client_ip = context.peer()
        client_id = self.seq
        self.seq+=1
        client_seq = 1 # sequence number of next expected request
        
        self.clients[client_id] = {"ip": client_ip, "seq": client_seq}
        if DEBUG:
            print("client_init received: " + str(request.rc))
            print("connected clients: " + str(self.clients))
        return lock_pb2.Int(rc=client_id, seq=client_seq)
    
    def lock_acquire(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq
        client_seq = self.clients[client_id]["seq"]
        if request_seq != client_seq:
            return lock_pb2.Response(status=lock_pb2.Status.SEQ_ERROR, seq = client_seq)

        print("lock_acquire received: " + str(request.client_id))

        self.waiting_list.append(request.client_id)

        while True:
            if self.waiting_list[0] == request.client_id:
                # essentially, head of waiting list is always current owner
                # could, in theory, remove self.lock_owner entirely but this might get confusing real fast
                self.lock_owner = request.client_id

                return lock_pb2.Response(status=lock_pb2.Status.SUCCESS)
            else:
                time.sleep(0.1)
    
    def lock_release(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq
        client_seq = self.clients[client_id]["seq"]
        if request_seq != client_seq:
            return lock_pb2.Response(status=lock_pb2.Status.SEQ_ERROR, seq = client_seq)
        
        print("lock_release received: " + str(request.client_id))
        
        self.clients[client_id]["seq"] += 1
        if self.lock_owner == request.client_id:
            # removes current owner from head of waiting list
            self.waiting_list.popleft()

            return lock_pb2.Response(status=lock_pb2.Status.SUCCESS, seq = self.clients[client_id]["seq"])
        else:
            # good idea to have this anyhow, as client could call release before ever calling acquire
            return lock_pb2.Response(status=lock_pb2.Status.FAILURE, seq = self.clients[client_id]["seq"])
    
    def file_append(self, request, context) -> lock_pb2.Response:
        client_id = request.client_id
        request_seq = request.seq
        client_seq = self.clients[client_id]["seq"]
        if request_seq != client_seq:
            return lock_pb2.Response(status=lock_pb2.Status.SEQ_ERROR, seq = client_seq)
        
        print("file_append received: " + str(request.filename))
        print("Lock owner" + str(self.lock_owner))
        print("Client ID" + str(request.client_id))
        self.clients[client_id]["seq"] += 1
        if self.lock_owner == request.client_id:
            filename = request.filename

            if os.path.isfile("./files/" + filename):
                file = open("./files/" + filename, 'ab')
                file.write(request.content)
                file.close()
                return lock_pb2.Response(status=lock_pb2.Status.SUCCESS, seq = self.clients[client_id]["seq"])
            else:
                return lock_pb2.Response(status=lock_pb2.Status.FILE_ERROR, seq = self.clients[client_id]["seq"])
        else:
            return lock_pb2.Response(status=lock_pb2.Status.FAILURE, seq = self.clients[client_id]["seq"])
    
    def client_close(self, request, context):
        # get process id and remove from set
        client_id = request.rc
        if client_id in self.clients:
            
            while self.lock_owner == client_id:
                time.sleep(0.01)
            del self.clients[client_id]

        if DEBUG:
            print("client_close received: " + str(request.rc))
            print("connected clients: " + str(self.clients))
            print()
        return lock_pb2.Int(rc=client_id, seq=0)
    
def create_files(n = 100):
    # create directory & files if necessary:
    if not os.path.exists("./files"):
        os.makedirs("./files")

        for i in range(n):
            with open("./files/file_" + str(i), "w") as f:
                f.write("")

def serve():
    port = "50051"
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    lock_pb2_grpc.add_LockServiceServicer_to_server(LockServer(), server)
    server.add_insecure_port("[::]:" + port)
    server.start()
    print("Server started, listening on " + port)
    server.wait_for_termination()

if __name__ == "__main__":

    create_files()
    logging.basicConfig()
    serve()
